{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ce36495-c0a7-437d-8c5b-e2fda0415d7d",
   "metadata": {},
   "source": [
    "# Testing Driver Drowsiness, Detection, Play Sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0db86831-d3ec-47d6-b643-394a929024fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.9.13)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from pygame import mixer  #alert sound\n",
    "import time\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033d87ac-1a9d-4475-a184-d6d9964a985e",
   "metadata": {},
   "source": [
    "## Sound alert if eyes are closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c8f69ab-7a87-40a1-87b6-a376005e93fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixer.init()\n",
    "alarm_sound = mixer.Sound(\"audio\\groovy_energy.mp3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbffd783-1dd0-4220-8cd3-46b7d9c0d6d6",
   "metadata": {},
   "source": [
    "## Haar cascades\n",
    "A Haar cascade classifier is a machine learning object detection program that identifies objects in an image and video.\n",
    "Haar is an algorithm that is capable of detecting objects in images, regardless of their location and scale in an image\n",
    "    \n",
    "Haar cascades have so many models to detect various parts of a human body like to detect eyes, frontal face, lower body, upper body, full body "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f444151f-f599-433e-9e7e-a517078b8c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detection = cv2.CascadeClassifier('haar_cascade\\haarcascade_frontalface_alt.xml')\n",
    "left_eye_detection = cv2.CascadeClassifier('haar_cascade\\haarcascade_lefteye_2splits.xml')\n",
    "right_eye_detection = cv2.CascadeClassifier('haar_cascade\\haarcascade_righteye_2splits.xml')\n",
    "labels =['Close','Open']\n",
    "\n",
    "#path = \"C:\\Users\\jngai\\AppData\\Roaming\\Python\\Python39\\site-packages\\cv2\\data\"\n",
    "#face_detection = cv2.CascadeClassifier(\"C:\\Users\\jngai\\AppData\\Roaming\\Python\\Python39\\site-packages\\cv2\\data\\haarcascade_frontalface_alt.xml\")\n",
    "#left_eye_detection = cv2.CascadeClassifier(\"C:\\Users\\jngai\\AppData\\Roaming\\Python\\Python39\\site-packages\\cv2\\data\\haarcascade_lefteye_2splits.xml\")\n",
    "#right_eye_detection = cv2.CascadeClassifier(\"C:\\Users\\jngai\\AppData\\Roaming\\Python\\Python39\\site-packages\\cv2\\data\\haarcascade_righteye_2splits.xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc8ece2-e35c-4375-b9b5-03da6b49f0dd",
   "metadata": {},
   "source": [
    "## Loading the created model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be7a993f-0c12-4c13-9bd4-3a1a1c2dc701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model we created\n",
    "\n",
    "#model = load_model(\"result_model.h5\")\n",
    "model = load_model(\"model-014.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fd6486-3d22-41f0-aae3-a866be91715f",
   "metadata": {},
   "source": [
    "## Using OpenCV to access the webcam and capture frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "761e25c8-3525-4bcc-908f-06ee2f247f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "\n",
    "# capture each frame\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "#check if the webcam is open\n",
    "if capture.isOpened():\n",
    "    capture = cv2.VideoCapture(0)\n",
    "if not capture.isOpened():\n",
    "    raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "font = cv2.FONT_HERSHEY_COMPLEX_SMALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "262d6da8-ba66-4a06-80a1-632579b00336",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declaring variables \n",
    "counter = 0\n",
    "time = 0\n",
    "thick = 2\n",
    "right_eye_pred=[99]\n",
    "left_eye_pred=[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa754312-1fd0-4ee0-b039-410f10b73701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Write anything to stop. q\n"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    ret, frame = capture.read()\n",
    "    height,width = frame.shape[:2] \n",
    "\n",
    "    #convert the captured image to grey color:\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #perform detection(this will return x,y coordinates , height , width of the boundary boxes object)\n",
    "    faces = face_detection.detectMultiScale(gray,minNeighbors=5,scaleFactor=1.1,minSize=(25,25))\n",
    "    left_eye = left_eye_detection.detectMultiScale(gray)\n",
    "    right_eye =   right_eye_detection.detectMultiScale(gray)\n",
    "\n",
    "    cv2.rectangle(frame, (0,height-50) , (100,height) , (0,0,0) , thickness=cv2.FILLED )\n",
    "    #cv2.rectangle(frame, (290,height-50) , (540,height) , (0,0,0) , thickness=cv2.FILLED )\n",
    "\n",
    "    #iterating over faces and drawing boundary boxes for each face:\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame, (x,y) , (x+w,y+h) , (100,100,100) , 1 )\n",
    "        \n",
    "    #iterating over right eye:\n",
    "    for (x,y,w,h) in right_eye:\n",
    "        #pull out the right eye image from the frame:\n",
    "        right_one=frame[y:y+h,x:x+w]\n",
    "        counter += 1\n",
    "        right_one = cv2.cvtColor(right_one,cv2.COLOR_BGR2GRAY)\n",
    "        right_one = cv2.resize(right_one,(24,24))\n",
    "        right_one = right_one/255\n",
    "        right_one =  right_one.reshape(24,24,-1)\n",
    "        right_one = np.expand_dims(right_one,axis=0)\n",
    "        #right_eye_pred = model.predict_classes(right_one)\n",
    "        #right_eye_pred = model.predict(right_one).astype(\"int32\")\n",
    "        right_eye_pred = np.argmax(model.predict(right_one),axis=1)\n",
    "        if(right_eye_pred[0] == 1):\n",
    "            labels = 'Open' \n",
    "        if(right_eye_pred[0]==0):\n",
    "            labels = 'Closed'\n",
    "        break\n",
    "\n",
    "    #iterating over left eye:\n",
    "    for (x,y,w,h) in left_eye:\n",
    "        #pull out the left eye image from the frame:\n",
    "        left_one=frame[y:y+h,x:x+w]\n",
    "        counter += 1\n",
    "        left_one = cv2.cvtColor(left_one,cv2.COLOR_BGR2GRAY)  \n",
    "        left_one = cv2.resize(left_one,(24,24))\n",
    "        left_one = left_one/255\n",
    "        left_one = left_one.reshape(24,24,-1)\n",
    "        left_one = np.expand_dims(left_one,axis=0)\n",
    "        #left_eye_pred = model.predict_classes(left_one)\n",
    "        #left_eye_pred = model.predict(left_one).astype(\"int32\")\n",
    "        left_eye_pred = np.argmax(model.predict(left_one),axis=1)\n",
    "        if(left_eye_pred[0] == 1):\n",
    "            labels ='Open'   \n",
    "        if(left_eye_pred[0] == 0):\n",
    "            labels ='Closed'\n",
    "        break\n",
    "\n",
    "    #checking - if the personâ€™s left eye and right eye are closed, time incremenets. If timer count> 10 make alert sound. If both eyes open, timer decrements and sound stops.\n",
    "\n",
    "    #print(right_eye_pred[0])\n",
    "    #print(\"l:\",left_eye_pred[0])\n",
    "    \n",
    "    if(right_eye_pred[0] == 0 and left_eye_pred[0] == 0):\n",
    "        time += 1\n",
    "        cv2.putText(frame,\"Inactive\",(10,height-20), font, 1,(255,255,255),1,cv2.LINE_AA)\n",
    "    # if(right_eye_pred[0]==1 or left_eye_pred[0]==1):\n",
    "    else:\n",
    "        time -= 1\n",
    "        cv2.putText(frame,\"Active\",(10,height-20), font, 1,(255,255,255),1,cv2.LINE_AA)\n",
    "        \n",
    "    \n",
    "    if(time<0):\n",
    "        time=0   \n",
    "    cv2.putText(frame,'Wake up Time !!:'+str(time),(100,height-20), font, 1,(0,0,255),1,cv2.LINE_AA)\n",
    "    if(time>5):\n",
    "        #person is falling asleep, therefore alert.\n",
    "        cv2.imwrite(os.path.join(path,'image.jpg'),frame)\n",
    "        try:\n",
    "            alarm_sound.play()\n",
    "            \n",
    "            input(\"Write anything to stop.\")\n",
    "            alarm_sound.stop()\n",
    "            \n",
    "        except:  # isplaying = False\n",
    "            pass\n",
    "        if(thick < 6):\n",
    "            thick = thick+2\n",
    "        else:\n",
    "            thick=thick-2\n",
    "            if(thick<2):\n",
    "                thick=2\n",
    "        cv2.rectangle(frame,(0,0),(width,height),(0,0,255),thick)\n",
    "    cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break   \n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2baafa-9600-49cf-95e3-d52e2306b8bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f314f9f7-823c-4f6d-b1ca-328dd3041529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e54c82bb-7d78-4c68-86ca-217f9feb2bfe",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "Haar cascades \n",
    "* https://github.com/opencv/opencv/tree/master/data/haarcascades\n",
    "* https://medium.com/analytics-vidhya/haar-cascades-explained-38210e57970d\n",
    "* https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/viola-cvpr-01.pdf\n",
    "\n",
    "Other sources:  \n",
    "https://stackoverflow.com/questions/68836551/keras-attributeerror-sequential-object-has-no-attribute-predict-classes/68841446#68841446https://stackoverflow.com/questions/68836551/keras-attributeerror-sequential-object-has-no-attribute-predict-classes/68841446#68841446\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388b7d88-93c9-4e78-8b82-c55bed6a0322",
   "metadata": {},
   "source": [
    "Notes:   \n",
    "* In this project, we use the haar cascade classifier and a CNN model to predict the status (eyes closed or open)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883aab6c-54e6-4437-965a-746256bb0b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra:\n",
    "    \n",
    "https://data-flair.training/blogs/python-project-driver-drowsiness-detection-system/\n",
    "\n",
    "#Sendgrid\n",
    "username: julesbabej@gmail.com\n",
    "password: babej01234567890"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
